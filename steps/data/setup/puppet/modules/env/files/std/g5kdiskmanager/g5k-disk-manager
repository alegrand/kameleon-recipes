#! /usr/bin/env ruby
# coding: utf-8

# INSTALLED BY PUPPET
# Location : puppet/modules/env/files/std/g5kdiskmanager/g5k-disk-manager

require 'open-uri'
require 'json'
require 'optparse'

DISABLE_DELAY = 2
ENABLE_DELAY = 1
ENABLE_LAST_DELAY = 2

def main
  options = parse_cmdline
  start
  if options[:on_boot]
    startup_service(options[:force])
  else
    manage_disks(options)
  end
  close
end

def start
  Dir.chdir(TMPDIR)
end

def close
  rmtmp
  exit 0
end

def rmtmp
  Dir.chdir('/root')
  sh("rm -rf #{TMPDIR}")
end

def sh(cmd)
  output = `#{cmd}`.chomp
  status = $?.exitstatus
  return [status, output]
end

# systemd log levels:
# see http://0pointer.net/blog/projects/journal-submit.html
# and http://man7.org/linux/man-pages/man3/syslog.3.html
def notice(msg)
  log_notice = 5 # normal, but significant, condition
  puts "<#{log_notice}> #{msg}"
end

def debug(msg)
  log_debug = 7 # debug-level message
  puts "<#{log_debug}> #{msg}" if DEBUG
end

def error(status, msg)
  log_err = 3 # error conditions
  puts "<#{log_err}> #{msg}"
  rmtmp
  exit status
end

def parse_cmdline
  options = {}
  OptionParser.new do |opts|
    opts.banner = 'Usage: g5k-disk-manager [--enable 1,2,3] [--disable 4,5]'
    opts.on('--on-boot', 'Enable all disks at boot time') do |v|
      options[:on_boot] = v
    end
    opts.on('--force', 'Force usage of --on-boot even if the node has been deployed by user') do |f|
      options[:force] = f
    end
    opts.on('--enable DISK_IDS', 'Enable disks') do |disks|
      options[:enable] = disks
    end
    opts.on('--disable DISK_IDS', 'Disable disks') do |disks|
      options[:disable] = disks
    end
    opts.on("-h", "--help", "Prints this help") do
      puts opts
      exit
    end
  end.parse!
  return options
end

# The aim of this function is to activate all disks of the node in a predefined
# order, so that sdb, sdc, ... devices names are always given to the same
# physical disks.
# It must be done just before g5k-checks is launched on the node, to avoid
# g5k-checks errors.
# See also /etc/systemd/system/g5k-disk-manager.service.
def startup_service(force)
  _status, hostname = sh('hostname')

  unless has_reservable_disks?
    notice "This cluster doesn't have reservable disks: exit service"
    close
  end

  if user_deploy?(hostname) and not force
    notice 'The environment is deployed manually by a user: the disks have not been activated'
    close
  end

  unless megacli_compliant?
    notice 'No compliant RAID controller was found: the disks have not been activated'
    close
  end

  # Get the disks identifiers
  physical_disks, virtual_disks = get_disks

  # If there is one virtual drive: exit, to exclude RAID 0 and RAID 1 configured
  # clusters
  num_virtual_drives = virtual_disks.count
  debug "num_virtual_drives = #{num_virtual_drives}"
  if num_virtual_drives >= 1
    notice 'One virtual drive of RAID disks is present: the disks have not been activated'
    close
  end

  # Remove the first disk from the list (first disk is the main disk sda)
  physical_disks.shift

  # Disable then enable the disks
  disable(physical_disks)
  num_enable_errors = enable(physical_disks)

  if num_enable_errors.zero?
    notice 'All disks have been activated with success'
  else
    error(1, "#{num_enable_errors} errors occured while enabling the disks")
  end
end

def manage_disks(options)
  error(2, 'No compliant RAID controller was found') unless megacli_compliant?

  physical_disks, _virtual_disks = get_disks
  disks_to_enable = disks_locations(physical_disks, options[:enable])
  disks_to_disable = disks_locations(physical_disks, options[:disable])

  # Array intersection
  if (disks_to_enable & disks_to_disable) != []
    error(3, 'You provided the same disk to enable and disable')
  end

  # First, we disable the disks (we will maybe re-enable them after)
  disable(disks_to_disable) unless disks_to_disable == []
  enable(disks_to_enable) unless disks_to_enable == []
end

def disks_locations(physical_disks, ids)
  return [] if ids.nil?
  ids = ids.split(',').map { |e| e.strip.to_i }
  disks = []
  ids.each do |id|
    # id == 0 corresponds to the main disk sda
    error(4, "Wrong disk id: #{id}") if id <= 0 || id >= physical_disks.length
    disks.push(physical_disks[id])
  end
  return disks
end

# Clusters with reservable disks are clusters whose
# reference-repository storage_devices property contains property
# reservation: true
def has_reservable_disks?
  ref_api = File.read('/etc/grid5000/ref-api.json')
  return JSON.parse(ref_api)['storage_devices'].select{|sd| sd['reservation']}.any?
end

# If property 'soft'='free', the standard environment is being
# deployed by an admin (outside a job) or phoenix.
# Else, it is a user that is deploying the standard environment
# For the different states, see:
# https://github.com/grid5000/g5k-api/blob/master/lib/oar/resource.rb#L45
def user_deploy?(hostname)
  url = G5K_API + '/sites/' + site(hostname) + '/status?disks=no&job_details=no&waiting=no&network_address=' + hostname
  hash = JSON::parse(open(url).read)
  status = hash['nodes'][hostname]
  debug("Node status: soft=#{status['soft']}, hard=#{status['hard']}")
  user_deploy = (status['hard'] == 'alive' and status['soft'] != 'free')
  return user_deploy
end

def cluster(hostname)
  return hostname.split('-')[0]
end

def site(hostname)
  return hostname.split('.')[1]
end

def megacli_compliant?
  # Get the number or RAID controllers supported by megacli
  # The return code of the command is the number of controllers supported
  num_controllers, _output = sh("#{MEGACLI} -AdpCount")
  compliant = (num_controllers != 0)
  return compliant
end

# This function retrieves the physical and virtual disk identifiers from
# the output of the megacli command.
# For both type of drives, the adapter is printed once on a single line
# and then are printed out the drives who belong to this adapter.
#
# A physical drive output looks like:
#
# Enclosure Device ID: 8
# Slot Number: 0
# Enclosure position: 1
# Device Id: 14
# WWN: 5002538c40be7492
# Sequence Number: 2
# Media Error Count: 0
# ... other lines
#
# A virtual one:
#
# Virtual Drive: 0 (Target Id: 0)
# Name                :SYSTEM
# RAID Level          : Primary-1, Secondary-0, RAID Level Qualifier-0
# Size                : 558.375 GB
# Sector Size         : 512
# ... other lines
#
# The physical drives have to be sorted by the Device ID to match the way
# Linux create the /dev/ devices special files (pci-scsi path order)
def get_disks
  status, output_pdlist = sh("#{MEGACLI} -PDList -aALL")
  unless status.zero?
    notice 'The command megacli failed to list physical drives'
    close
  end

  status, output_vdlist = sh("#{MEGACLI} -LDInfo -Lall -aall")
  unless status.zero?
    notice 'The command megacli failed to list virtual drives'
    close
  end

  physical_disks = []
  virtual_disks = []

  adapter_regexp = /^Adapter\s#?(\d+).*$/
  enclosure_regexp = /^Enclosure\sDevice\sID:\s+(\d+)$/
  slot_regexp = /^Slot\sNumber:\s+(\d+)$/
  device_id_regexp = /^Device\sId:\s+(\d+)$/
  virtual_drive_regexp = /^Virtual\sDrive:\s+(\d+).+$/

  adapter = ""
  enclosure = ""
  slot = ""

  output_pdlist.each_line do |line|
    if m = adapter_regexp.match(line)
      adapter = m[1].to_i
    elsif m = enclosure_regexp.match(line)
      enclosure = m[1].to_i
    elsif m = slot_regexp.match(line)
      slot = m[1].to_i
    elsif m = device_id_regexp.match(line)
      physical_disks << { adapter: adapter, enclosure: enclosure, slot: slot, device_id: m[1].to_i }
    end

    physical_disks.sort_by!{ |p_disk| p_disk[:device_id] }
  end

  adapter = ""

  output_vdlist.each_line do |line|
    if m = adapter_regexp.match(line)
      adapter = m[1].to_i
    elsif m = virtual_drive_regexp.match(line)
      virtual_disks << { adapter: adapter, drive: m[1].to_i }
    end
  end

  return [physical_disks, virtual_disks]
end

# Enable the disks
# The megacli command changes the the state of the drive from Unconfigured Good
# to JBOD (Just a Bunch of Disks).
# A new drive in JBOD state is exposed to the host operating system as a
# stand-alone drive. Drives in JBOD drive state are not part of the RAID
# configuration.
def enable(physical_disks)
  num_enable_errors = 0
  physical_disks.each do |disk|
    # Sleep a bit before enabling to give the kernel time to detect disks that were
    # previously removed, or disks that were just enabled.
    # If we do that too fast, the kernel might pick up disks in a random order.
    # See bug https://intranet.grid5000.fr/bugzilla/show_bug.cgi?id=9238 for details.
    sleep(ENABLE_DELAY)
    status, _output = sh("#{MEGACLI} -PDMakeJBOD -PhysDrv [#{disk[:enclosure]}:#{disk[:slot]}] -a#{disk[:adapter]}")
    debug "Enabling disk #{disk} => Return code = #{status}"
    num_enable_errors += 1 unless status.zero?
  end
  # Also sleep after enabling the last disk
  sleep(ENABLE_LAST_DELAY)
  return num_enable_errors
end

# Disable the disks
# The megacli command changes the state of the drive from JBOD to
# Unconfigured Good. When in Unconfigured Good state, the disk is accessible
# to the RAID controller but not configured as a part of a virtual disk
# or as a hot spare.
def disable(physical_disks)
  num_disable_errors = 0
  physical_disks.each do |disk|
    status, _output = sh("#{MEGACLI} -PDMakeGood -PhysDrv [#{disk[:enclosure]}:#{disk[:slot]}] -force -a#{disk[:adapter]}")
    debug "Disabling disk #{disk} => Return code = #{status}"
    num_disable_errors += 1 unless status.zero?
  end
  sleep(DISABLE_DELAY)
  return num_disable_errors
end

# Main program

MEGACLI = '/usr/sbin/megacli'.freeze

G5K_API = 'https://api.grid5000.fr/stable'
_status, TMPDIR = sh('mktemp -d /tmp/tmp.g5k-disk-manager.XXXXXX')
DEBUG = true
main
